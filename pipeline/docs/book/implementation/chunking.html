<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Chunking Strategy - Pipeline Developer Guide</title>


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        <link rel="stylesheet" href="../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="../highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="../tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "../";
            const default_light_theme = "light";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "../searchindex.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="../toc.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="../toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Pipeline Developer Guide</h1>

                    <div class="right-buttons">
                        <a href="../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <i class="fa fa-spinner fa-spin"></i>
                            </div>
                        </div>
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="chunking-strategy"><a class="header" href="#chunking-strategy">Chunking Strategy</a></h1>
<p><strong>Version:</strong> 0.1.0
<strong>Date:</strong> October 2025
<strong>SPDX-License-Identifier:</strong> BSD-3-Clause
<strong>License File:</strong> See the LICENSE file in the project root.
<strong>Copyright:</strong> © 2025 Michael Gardner, A Bit of Help, Inc.
<strong>Authors:</strong> Michael Gardner
<strong>Status:</strong> Draft</p>
<p>This chapter provides a comprehensive overview of the file chunking strategy in the adaptive pipeline system. Learn how files are split into manageable chunks, how chunk sizes are optimized, and how chunking enables efficient parallel processing.</p>
<hr />
<h2 id="table-of-contents"><a class="header" href="#table-of-contents">Table of Contents</a></h2>
<ul>
<li><a href="#overview">Overview</a></li>
<li><a href="#chunking-architecture">Chunking Architecture</a></li>
<li><a href="#chunk-size-selection">Chunk Size Selection</a></li>
<li><a href="#chunking-algorithm">Chunking Algorithm</a></li>
<li><a href="#optimal-sizing-strategy">Optimal Sizing Strategy</a></li>
<li><a href="#memory-management">Memory Management</a></li>
<li><a href="#parallel-processing">Parallel Processing</a></li>
<li><a href="#adaptive-chunking">Adaptive Chunking</a></li>
<li><a href="#performance-characteristics">Performance Characteristics</a></li>
<li><a href="#usage-examples">Usage Examples</a></li>
<li><a href="#best-practices">Best Practices</a></li>
<li><a href="#troubleshooting">Troubleshooting</a></li>
<li><a href="#testing-strategies">Testing Strategies</a></li>
<li><a href="#next-steps">Next Steps</a></li>
</ul>
<hr />
<h2 id="overview"><a class="header" href="#overview">Overview</a></h2>
<p><strong>Chunking</strong> is the process of dividing files into smaller, manageable pieces (chunks) that can be processed independently. This strategy enables efficient memory usage, parallel processing, and scalable file handling regardless of file size.</p>
<h3 id="key-benefits"><a class="header" href="#key-benefits">Key Benefits</a></h3>
<ul>
<li><strong>Memory Efficiency</strong>: Process files larger than available RAM</li>
<li><strong>Parallel Processing</strong>: Process multiple chunks concurrently</li>
<li><strong>Fault Tolerance</strong>: Failed chunks can be retried independently</li>
<li><strong>Progress Tracking</strong>: Track progress at chunk granularity</li>
<li><strong>Scalability</strong>: Handle files from bytes to terabytes</li>
</ul>
<h3 id="chunking-workflow"><a class="header" href="#chunking-workflow">Chunking Workflow</a></h3>
<pre><code class="language-text">Input File (100 MB)
        ↓
[Chunking Strategy]
        ↓
┌──────────┬──────────┬──────────┬──────────┐
│ Chunk 0  │ Chunk 1  │ Chunk 2  │ Chunk 3  │
│ (0-25MB) │(25-50MB) │(50-75MB) │(75-100MB)│
└──────────┴──────────┴──────────┴──────────┘
        ↓ parallel processing
┌──────────┬──────────┬──────────┬──────────┐
│Processed │Processed │Processed │Processed │
│ Chunk 0  │ Chunk 1  │ Chunk 2  │ Chunk 3  │
└──────────┴──────────┴──────────┴──────────┘
        ↓
Output File (processed)
</code></pre>
<h3 id="design-principles"><a class="header" href="#design-principles">Design Principles</a></h3>
<ol>
<li><strong>Predictable Memory</strong>: Bounded memory usage regardless of file size</li>
<li><strong>Optimal Sizing</strong>: Empirically optimized chunk sizes for performance</li>
<li><strong>Independent Processing</strong>: Each chunk can be processed in isolation</li>
<li><strong>Ordered Reassembly</strong>: Chunks maintain sequence for correct reassembly</li>
<li><strong>Adaptive Strategy</strong>: Chunk size adapts to file size and system resources</li>
</ol>
<hr />
<h2 id="chunking-architecture"><a class="header" href="#chunking-architecture">Chunking Architecture</a></h2>
<p>The chunking system uses a combination of value objects and algorithms to efficiently divide files.</p>
<h3 id="chunking-components"><a class="header" href="#chunking-components">Chunking Components</a></h3>
<pre><code class="language-text">┌─────────────────────────────────────────────────────────┐
│                 Chunking Strategy                        │
│                                                          │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐ │
│  │  ChunkSize   │  │ FileChunk    │  │  Chunking    │ │
│  │   (1B-512MB) │  │ (immutable)  │  │  Algorithm   │ │
│  └──────────────┘  └──────────────┘  └──────────────┘ │
│                                                          │
└─────────────────────────────────────────────────────────┘
                         ↓
┌─────────────────────────────────────────────────────────┐
│              Optimal Size Calculation                    │
│                                                          │
│  File Size → optimal_for_file_size() → ChunkSize       │
│                                                          │
│  - Small files  (&lt;10 MB):    64-256 KB chunks          │
│  - Medium files (10-500 MB): 2-16 MB chunks            │
│  - Large files  (500MB-2GB): 64 MB chunks              │
│  - Huge files   (&gt;2 GB):     128 MB chunks             │
└─────────────────────────────────────────────────────────┘
</code></pre>
<h3 id="chunk-lifecycle"><a class="header" href="#chunk-lifecycle">Chunk Lifecycle</a></h3>
<pre><code class="language-text">1. Size Determination
   - Calculate optimal chunk size based on file size
   - Adjust for available memory if needed
   ↓
2. File Division
   - Read file in chunk-sized pieces
   - Create FileChunk with sequence number and offset
   ↓
3. Chunk Processing
   - Apply pipeline stages to each chunk
   - Process chunks in parallel if enabled
   ↓
4. Chunk Reassembly
   - Combine processed chunks by sequence number
   - Write to output file
</code></pre>
<hr />
<h2 id="chunk-size-selection"><a class="header" href="#chunk-size-selection">Chunk Size Selection</a></h2>
<p>Chunk size is critical for performance and memory efficiency. The system supports validated sizes from 1 byte to 512 MB.</p>
<h3 id="size-constraints"><a class="header" href="#size-constraints">Size Constraints</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// ChunkSize constants
ChunkSize::MIN_SIZE  // 1 byte
ChunkSize::MAX_SIZE  // 512 MB
ChunkSize::DEFAULT   // 1 MB
<span class="boring">}</span></code></pre></pre>
<h3 id="creating-chunk-sizes"><a class="header" href="#creating-chunk-sizes">Creating Chunk Sizes</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use pipeline_domain::ChunkSize;

// From bytes
let chunk = ChunkSize::new(1024 * 1024)?;  // 1 MB

// From kilobytes
let chunk_kb = ChunkSize::from_kb(512)?;  // 512 KB

// From megabytes
let chunk_mb = ChunkSize::from_mb(16)?;  // 16 MB

// Default size
let default_chunk = ChunkSize::default();  // 1 MB
<span class="boring">}</span></code></pre></pre>
<h3 id="size-validation"><a class="header" href="#size-validation">Size Validation</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// ✅ Valid sizes
let valid = ChunkSize::new(64 * 1024)?;  // 64 KB - valid

// ❌ Invalid: too small
let too_small = ChunkSize::new(0);  // Error: must be ≥ 1 byte
assert!(too_small.is_err());

// ❌ Invalid: too large
let too_large = ChunkSize::new(600 * 1024 * 1024);  // Error: must be ≤ 512 MB
assert!(too_large.is_err());
<span class="boring">}</span></code></pre></pre>
<h3 id="size-trade-offs"><a class="header" href="#size-trade-offs">Size Trade-offs</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Chunk Size</th><th>Memory Usage</th><th>I/O Overhead</th><th>Parallelism</th><th>Best For</th></tr></thead><tbody>
<tr><td><strong>Small (64-256 KB)</strong></td><td>Low</td><td>High</td><td>Excellent</td><td>Small files, limited memory</td></tr>
<tr><td><strong>Medium (1-16 MB)</strong></td><td>Moderate</td><td>Moderate</td><td>Good</td><td>Most use cases</td></tr>
<tr><td><strong>Large (64-128 MB)</strong></td><td>High</td><td>Low</td><td>Limited</td><td>Large files, ample memory</td></tr>
</tbody></table>
</div>
<hr />
<h2 id="chunking-algorithm"><a class="header" href="#chunking-algorithm">Chunking Algorithm</a></h2>
<p>The chunking algorithm divides files into sequential chunks with proper metadata.</p>
<h3 id="basic-chunking-process"><a class="header" href="#basic-chunking-process">Basic Chunking Process</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn chunk_file(
    file_path: &amp;Path,
    chunk_size: ChunkSize,
) -&gt; Result&lt;Vec&lt;FileChunk&gt;, PipelineError&gt; {
    let file = File::open(file_path)?;
    let file_size = file.metadata()?.len();
    let mut chunks = Vec::new();
    let mut offset = 0;
    let mut sequence = 0;

    // Read file in chunks
    let mut reader = BufReader::new(file);
    let mut buffer = vec![0u8; chunk_size.bytes()];

    loop {
        let bytes_read = reader.read(&amp;mut buffer)?;
        if bytes_read == 0 {
            break;  // EOF
        }

        let data = buffer[..bytes_read].to_vec();
        let is_final = offset + bytes_read as u64 &gt;= file_size;

        let chunk = FileChunk::new(sequence, offset, data, is_final)?;
        chunks.push(chunk);

        offset += bytes_read as u64;
        sequence += 1;
    }

    Ok(chunks)
}
<span class="boring">}</span></code></pre></pre>
<h3 id="chunk-metadata"><a class="header" href="#chunk-metadata">Chunk Metadata</a></h3>
<p>Each chunk contains essential metadata:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct FileChunk {
    id: Uuid,                 // Unique chunk identifier
    sequence_number: u64,     // Order in file (0-based)
    offset: u64,              // Byte offset in original file
    size: ChunkSize,          // Actual chunk size
    data: Vec&lt;u8&gt;,            // Chunk data
    checksum: Option&lt;String&gt;, // Optional checksum
    is_final: bool,           // Last chunk flag
    created_at: DateTime&lt;Utc&gt;,// Creation timestamp
}
<span class="boring">}</span></code></pre></pre>
<h3 id="calculating-chunk-count"><a class="header" href="#calculating-chunk-count">Calculating Chunk Count</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Calculate number of chunks needed
let file_size = 100 * 1024 * 1024;  // 100 MB
let chunk_size = ChunkSize::from_mb(4)?;  // 4 MB chunks

let num_chunks = chunk_size.chunks_needed_for_file(file_size);
println!("Need {} chunks", num_chunks);  // 25 chunks
<span class="boring">}</span></code></pre></pre>
<hr />
<h2 id="optimal-sizing-strategy"><a class="header" href="#optimal-sizing-strategy">Optimal Sizing Strategy</a></h2>
<p>The system uses empirically optimized chunk sizes based on comprehensive benchmarking.</p>
<h3 id="optimization-strategy"><a class="header" href="#optimization-strategy">Optimization Strategy</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn optimal_for_file_size(file_size: u64) -&gt; ChunkSize {
    let optimal_size = match file_size {
        // Small files: smaller chunks
        0..=1_048_576 =&gt; 64 * 1024,           // 64KB for ≤ 1MB
        1_048_577..=10_485_760 =&gt; 256 * 1024, // 256KB for ≤ 10MB

        // Medium files: empirically optimized
        10_485_761..=52_428_800 =&gt; 2 * 1024 * 1024,  // 2MB for ≤ 50MB
        52_428_801..=524_288_000 =&gt; 16 * 1024 * 1024, // 16MB for 50-500MB

        // Large files: larger chunks for efficiency
        524_288_001..=2_147_483_648 =&gt; 64 * 1024 * 1024, // 64MB for 500MB-2GB

        // Huge files: maximum throughput
        _ =&gt; 128 * 1024 * 1024, // 128MB for &gt;2GB
    };

    ChunkSize { bytes: optimal_size.clamp(MIN_SIZE, MAX_SIZE) }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="empirical-results"><a class="header" href="#empirical-results">Empirical Results</a></h3>
<p>Benchmarking results that informed this strategy:</p>
<div class="table-wrapper"><table><thead><tr><th>File Size</th><th>Chunk Size</th><th>Throughput</th><th>Improvement</th></tr></thead><tbody>
<tr><td>100 MB</td><td>16 MB</td><td>~300 MB/s</td><td>+43.7% vs 2 MB</td></tr>
<tr><td>500 MB</td><td>16 MB</td><td>~320 MB/s</td><td>+56.2% vs 4 MB</td></tr>
<tr><td>2 GB</td><td>128 MB</td><td>~350 MB/s</td><td>Baseline</td></tr>
</tbody></table>
</div>
<h3 id="using-optimal-sizes"><a class="header" href="#using-optimal-sizes">Using Optimal Sizes</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Automatically select optimal chunk size
let file_size = 100 * 1024 * 1024;  // 100 MB
let optimal = ChunkSize::optimal_for_file_size(file_size);

println!("Optimal chunk size: {} MB", optimal.megabytes());  // 16 MB

// Check if current size is optimal
let current = ChunkSize::from_mb(4)?;
if !current.is_optimal_for_file(file_size) {
    println!("Warning: chunk size may be suboptimal");
}
<span class="boring">}</span></code></pre></pre>
<hr />
<h2 id="memory-management"><a class="header" href="#memory-management">Memory Management</a></h2>
<p>Chunking enables predictable memory usage regardless of file size.</p>
<h3 id="bounded-memory-usage"><a class="header" href="#bounded-memory-usage">Bounded Memory Usage</a></h3>
<pre><code class="language-text">Without Chunking:
  File: 10 GB
  Memory: 10 GB (entire file in memory)

With Chunking (16 MB chunks):
  File: 10 GB
  Memory: 16 MB (single chunk in memory)
  Reduction: 640x less memory!
</code></pre>
<h3 id="memory-adaptive-chunking"><a class="header" href="#memory-adaptive-chunking">Memory-Adaptive Chunking</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Adjust chunk size based on available memory
let available_memory = 100 * 1024 * 1024;  // 100 MB available
let max_parallel_chunks = 4;

let chunk_size = ChunkSize::from_mb(32)?;  // Desired 32 MB
let adjusted = chunk_size.adjust_for_memory(
    available_memory,
    max_parallel_chunks,
)?;

println!("Adjusted chunk size: {} MB", adjusted.megabytes());
// 25 MB (100 MB / 4 chunks)
<span class="boring">}</span></code></pre></pre>
<h3 id="memory-footprint-calculation"><a class="header" href="#memory-footprint-calculation">Memory Footprint Calculation</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn calculate_memory_footprint(
    chunk_size: ChunkSize,
    parallel_chunks: usize,
) -&gt; usize {
    // Base memory per chunk
    let per_chunk = chunk_size.bytes();

    // Additional overhead (metadata, buffers, etc.)
    let overhead_per_chunk = 1024;  // ~1 KB overhead

    // Total memory footprint
    parallel_chunks * (per_chunk + overhead_per_chunk)
}

let chunk_size = ChunkSize::from_mb(4)?;
let memory = calculate_memory_footprint(chunk_size, 4);
println!("Memory footprint: {} MB", memory / (1024 * 1024));
// ~16 MB total
<span class="boring">}</span></code></pre></pre>
<hr />
<h2 id="parallel-processing"><a class="header" href="#parallel-processing">Parallel Processing</a></h2>
<p>Chunking enables efficient parallel processing of file data.</p>
<h3 id="parallel-chunk-processing"><a class="header" href="#parallel-chunk-processing">Parallel Chunk Processing</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use futures::future::try_join_all;

async fn process_chunks_parallel(
    chunks: Vec&lt;FileChunk&gt;,
) -&gt; Result&lt;Vec&lt;FileChunk&gt;, PipelineError&gt; {
    // Process chunks in parallel
    let futures = chunks.into_iter().map(|chunk| {
        tokio::spawn(async move {
            process_chunk(chunk).await
        })
    });

    // Wait for all to complete
    let results = try_join_all(futures).await?;
    Ok(results.into_iter().collect::&lt;Result&lt;Vec&lt;_&gt;, _&gt;&gt;()?)
}
<span class="boring">}</span></code></pre></pre>
<h3 id="parallelism-trade-offs"><a class="header" href="#parallelism-trade-offs">Parallelism Trade-offs</a></h3>
<pre><code class="language-text">Sequential Processing:
  Time = num_chunks × time_per_chunk
  Memory = 1 × chunk_size

Parallel Processing (N threads):
  Time = (num_chunks / N) × time_per_chunk
  Memory = N × chunk_size
</code></pre>
<h3 id="optimal-parallelism"><a class="header" href="#optimal-parallelism">Optimal Parallelism</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Calculate optimal parallelism
fn optimal_parallelism(
    file_size: u64,
    chunk_size: ChunkSize,
    available_memory: usize,
    cpu_cores: usize,
) -&gt; usize {
    let num_chunks = chunk_size.chunks_needed_for_file(file_size) as usize;

    // Memory-based limit
    let memory_limit = available_memory / chunk_size.bytes();

    // CPU-based limit
    let cpu_limit = cpu_cores;

    // Chunk count limit
    let chunk_limit = num_chunks;

    // Take minimum of all limits
    memory_limit.min(cpu_limit).min(chunk_limit).max(1)
}

let file_size = 100 * 1024 * 1024;
let chunk_size = ChunkSize::from_mb(4)?;
let parallelism = optimal_parallelism(
    file_size,
    chunk_size,
    64 * 1024 * 1024,  // 64 MB available
    8,                  // 8 CPU cores
);
println!("Optimal parallelism: {} chunks", parallelism);
<span class="boring">}</span></code></pre></pre>
<hr />
<h2 id="adaptive-chunking"><a class="header" href="#adaptive-chunking">Adaptive Chunking</a></h2>
<p>The system can adapt chunk sizes dynamically based on conditions.</p>
<h3 id="adaptive-sizing-triggers"><a class="header" href="#adaptive-sizing-triggers">Adaptive Sizing Triggers</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub enum AdaptiveTrigger {
    MemoryPressure,      // Reduce chunk size due to low memory
    SlowPerformance,     // Increase chunk size for better throughput
    NetworkLatency,      // Reduce chunk size for streaming
    CpuUtilization,      // Adjust based on CPU usage
}
<span class="boring">}</span></code></pre></pre>
<h3 id="dynamic-adjustment"><a class="header" href="#dynamic-adjustment">Dynamic Adjustment</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>async fn adaptive_chunking(
    file_path: &amp;Path,
    initial_chunk_size: ChunkSize,
) -&gt; Result&lt;Vec&lt;FileChunk&gt;, PipelineError&gt; {
    let mut chunk_size = initial_chunk_size;
    let mut chunks = Vec::new();
    let mut performance_samples = Vec::new();

    loop {
        let start = Instant::now();

        // Read next chunk
        let chunk = read_next_chunk(file_path, chunk_size)?;
        if chunk.is_none() {
            break;
        }

        let duration = start.elapsed();
        performance_samples.push(duration);

        chunks.push(chunk.unwrap());

        // Adapt chunk size based on performance
        if performance_samples.len() &gt;= 5 {
            let avg_time = performance_samples.iter().sum::&lt;Duration&gt;() / 5;

            if avg_time &gt; Duration::from_millis(100) {
                // Too slow, increase chunk size
                chunk_size = adjust_chunk_size(chunk_size, 1.5)?;
            } else if avg_time &lt; Duration::from_millis(10) {
                // Too fast, reduce overhead by increasing size
                chunk_size = adjust_chunk_size(chunk_size, 1.2)?;
            }

            performance_samples.clear();
        }
    }

    Ok(chunks)
}

fn adjust_chunk_size(
    current: ChunkSize,
    factor: f64,
) -&gt; Result&lt;ChunkSize, PipelineError&gt; {
    let new_size = (current.bytes() as f64 * factor) as usize;
    ChunkSize::new(new_size)
}
<span class="boring">}</span></code></pre></pre>
<hr />
<h2 id="performance-characteristics"><a class="header" href="#performance-characteristics">Performance Characteristics</a></h2>
<p>Chunking performance varies based on size and system characteristics.</p>
<h3 id="throughput-by-chunk-size"><a class="header" href="#throughput-by-chunk-size">Throughput by Chunk Size</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Chunk Size</th><th>Read Speed</th><th>Write Speed</th><th>CPU Usage</th><th>Memory</th></tr></thead><tbody>
<tr><td><strong>64 KB</strong></td><td>~40 MB/s</td><td>~35 MB/s</td><td>15%</td><td>Low</td></tr>
<tr><td><strong>1 MB</strong></td><td>~120 MB/s</td><td>~100 MB/s</td><td>20%</td><td>Low</td></tr>
<tr><td><strong>16 MB</strong></td><td>~300 MB/s</td><td>~280 MB/s</td><td>25%</td><td>Medium</td></tr>
<tr><td><strong>64 MB</strong></td><td>~320 MB/s</td><td>~300 MB/s</td><td>30%</td><td>High</td></tr>
<tr><td><strong>128 MB</strong></td><td>~350 MB/s</td><td>~320 MB/s</td><td>35%</td><td>High</td></tr>
</tbody></table>
</div>
<p><em>Benchmarks on NVMe SSD with 8-core CPU</em></p>
<h3 id="latency-characteristics"><a class="header" href="#latency-characteristics">Latency Characteristics</a></h3>
<pre><code class="language-text">Small Chunks (64 KB):
  - Low latency per chunk: ~1-2ms
  - High overhead: many chunks
  - Good for: streaming, low memory

Large Chunks (128 MB):
  - High latency per chunk: ~400ms
  - Low overhead: few chunks
  - Good for: throughput, batch processing
</code></pre>
<h3 id="performance-optimization"><a class="header" href="#performance-optimization">Performance Optimization</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Benchmark different chunk sizes
async fn benchmark_chunk_sizes(
    file_path: &amp;Path,
    sizes: &amp;[ChunkSize],
) -&gt; Vec&lt;(ChunkSize, Duration)&gt; {
    let mut results = Vec::new();

    for &amp;size in sizes {
        let start = Instant::now();
        let _ = chunk_file(file_path, size).await.unwrap();
        let duration = start.elapsed();

        results.push((size, duration));
    }

    results.sort_by_key(|(_, duration)| *duration);
    results
}

// Usage
let sizes = vec![
    ChunkSize::from_kb(64)?,
    ChunkSize::from_mb(1)?,
    ChunkSize::from_mb(16)?,
    ChunkSize::from_mb(64)?,
];

let results = benchmark_chunk_sizes(Path::new("./test.dat"), &amp;sizes).await;
for (size, duration) in results {
    println!("{} MB: {:?}", size.megabytes(), duration);
}
<span class="boring">}</span></code></pre></pre>
<hr />
<h2 id="usage-examples"><a class="header" href="#usage-examples">Usage Examples</a></h2>
<h3 id="example-1-basic-chunking"><a class="header" href="#example-1-basic-chunking">Example 1: Basic Chunking</a></h3>
<pre><pre class="playground"><code class="language-rust">use pipeline_domain::{ChunkSize, FileChunk};
use std::path::Path;

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    let file_path = Path::new("./input.dat");

    // Determine optimal chunk size
    let file_size = std::fs::metadata(file_path)?.len();
    let chunk_size = ChunkSize::optimal_for_file_size(file_size);

    println!("File size: {} MB", file_size / (1024 * 1024));
    println!("Chunk size: {} MB", chunk_size.megabytes());

    // Chunk the file
    let chunks = chunk_file(file_path, chunk_size)?;
    println!("Created {} chunks", chunks.len());

    Ok(())
}</code></pre></pre>
<h3 id="example-2-memory-adaptive-chunking"><a class="header" href="#example-2-memory-adaptive-chunking">Example 2: Memory-Adaptive Chunking</a></h3>
<pre><pre class="playground"><code class="language-rust">#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    let file_path = Path::new("./large_file.dat");
    let file_size = std::fs::metadata(file_path)?.len();

    // Start with optimal size
    let optimal = ChunkSize::optimal_for_file_size(file_size);

    // Adjust for available memory
    let available_memory = 100 * 1024 * 1024;  // 100 MB
    let max_parallel = 4;

    let chunk_size = optimal.adjust_for_memory(
        available_memory,
        max_parallel,
    )?;

    println!("Optimal: {} MB", optimal.megabytes());
    println!("Adjusted: {} MB", chunk_size.megabytes());

    let chunks = chunk_file(file_path, chunk_size)?;
    println!("Created {} chunks", chunks.len());

    Ok(())
}</code></pre></pre>
<h3 id="example-3-parallel-chunk-processing"><a class="header" href="#example-3-parallel-chunk-processing">Example 3: Parallel Chunk Processing</a></h3>
<pre><pre class="playground"><code class="language-rust">use futures::future::try_join_all;

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    let file_path = Path::new("./input.dat");
    let chunk_size = ChunkSize::from_mb(16)?;

    // Create chunks
    let chunks = chunk_file(file_path, chunk_size)?;
    println!("Processing {} chunks in parallel", chunks.len());

    // Process in parallel
    let futures = chunks.into_iter().map(|chunk| {
        tokio::spawn(async move {
            // Simulate processing
            tokio::time::sleep(Duration::from_millis(10)).await;
            process_chunk(chunk).await
        })
    });

    let results = try_join_all(futures).await?;
    let processed: Vec&lt;_&gt; = results.into_iter()
        .collect::&lt;Result&lt;Vec&lt;_&gt;, _&gt;&gt;()?;

    println!("Processed {} chunks", processed.len());

    Ok(())
}

async fn process_chunk(chunk: FileChunk) -&gt; Result&lt;FileChunk, PipelineError&gt; {
    // Transform chunk data
    let transformed_data = chunk.data().to_vec();
    Ok(FileChunk::new(
        chunk.sequence_number(),
        chunk.offset(),
        transformed_data,
        chunk.is_final(),
    )?)
}</code></pre></pre>
<h3 id="example-4-adaptive-chunking"><a class="header" href="#example-4-adaptive-chunking">Example 4: Adaptive Chunking</a></h3>
<pre><pre class="playground"><code class="language-rust">#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    let file_path = Path::new("./test.dat");
    let initial_size = ChunkSize::from_mb(4)?;

    println!("Starting with {} MB chunks", initial_size.megabytes());

    let chunks = adaptive_chunking(file_path, initial_size).await?;

    println!("Created {} chunks with adaptive sizing", chunks.len());

    // Analyze chunk sizes
    for chunk in &amp;chunks[0..5.min(chunks.len())] {
        println!("Chunk {}: {} bytes",
            chunk.sequence_number(),
            chunk.size().bytes()
        );
    }

    Ok(())
}</code></pre></pre>
<hr />
<h2 id="best-practices"><a class="header" href="#best-practices">Best Practices</a></h2>
<h3 id="1-use-optimal-chunk-sizes"><a class="header" href="#1-use-optimal-chunk-sizes">1. Use Optimal Chunk Sizes</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// ✅ Good: Use optimal sizing
let file_size = metadata(path)?.len();
let chunk_size = ChunkSize::optimal_for_file_size(file_size);

// ❌ Bad: Fixed size for all files
let chunk_size = ChunkSize::from_mb(1)?;
<span class="boring">}</span></code></pre></pre>
<h3 id="2-consider-memory-constraints"><a class="header" href="#2-consider-memory-constraints">2. Consider Memory Constraints</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// ✅ Good: Adjust for available memory
let chunk_size = optimal.adjust_for_memory(
    available_memory,
    max_parallel_chunks,
)?;

// ❌ Bad: Ignore memory limits
let chunk_size = ChunkSize::from_mb(128)?;  // May cause OOM
<span class="boring">}</span></code></pre></pre>
<h3 id="3-validate-chunk-sizes"><a class="header" href="#3-validate-chunk-sizes">3. Validate Chunk Sizes</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// ✅ Good: Validate user input
let user_size_mb = 32;
let file_size = metadata(path)?.len();

match ChunkSize::validate_user_input(user_size_mb, file_size) {
    Ok(bytes) =&gt; {
        let chunk_size = ChunkSize::new(bytes)?;
        // Use validated size
    },
    Err(msg) =&gt; {
        eprintln!("Invalid chunk size: {}", msg);
        // Use optimal instead
        let chunk_size = ChunkSize::optimal_for_file_size(file_size);
    },
}
<span class="boring">}</span></code></pre></pre>
<h3 id="4-monitor-chunk-processing"><a class="header" href="#4-monitor-chunk-processing">4. Monitor Chunk Processing</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// ✅ Good: Track progress
for (i, chunk) in chunks.iter().enumerate() {
    let start = Instant::now();
    process_chunk(chunk)?;
    let duration = start.elapsed();

    println!("Chunk {}/{}: {:?}",
        i + 1, chunks.len(), duration);
}
<span class="boring">}</span></code></pre></pre>
<h3 id="5-handle-edge-cases"><a class="header" href="#5-handle-edge-cases">5. Handle Edge Cases</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// ✅ Good: Handle small files
if file_size &lt; chunk_size.bytes() as u64 {
    // File fits in single chunk
    let chunk_size = ChunkSize::new(file_size as usize)?;
}

// ✅ Good: Handle empty files
if file_size == 0 {
    return Ok(Vec::new());  // No chunks needed
}
<span class="boring">}</span></code></pre></pre>
<h3 id="6-use-checksums-for-integrity"><a class="header" href="#6-use-checksums-for-integrity">6. Use Checksums for Integrity</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// ✅ Good: Add checksums to chunks
let chunk = FileChunk::new(seq, offset, data, is_final)?
    .with_calculated_checksum();

// Verify before processing
if !chunk.verify_checksum() {
    return Err(PipelineError::ChecksumMismatch);
}
<span class="boring">}</span></code></pre></pre>
<hr />
<h2 id="troubleshooting"><a class="header" href="#troubleshooting">Troubleshooting</a></h2>
<h3 id="issue-1-out-of-memory-with-large-chunks"><a class="header" href="#issue-1-out-of-memory-with-large-chunks">Issue 1: Out of Memory with Large Chunks</a></h3>
<p><strong>Symptom:</strong></p>
<pre><code class="language-text">Error: Out of memory allocating chunk
</code></pre>
<p><strong>Solutions:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// 1. Reduce chunk size
let smaller = ChunkSize::from_mb(4)?;  // Instead of 128 MB

// 2. Adjust for available memory
let adjusted = chunk_size.adjust_for_memory(
    available_memory,
    max_parallel,
)?;

// 3. Process sequentially instead of parallel
for chunk in chunks {
    process_chunk(chunk).await?;
    // Chunk dropped, memory freed
}
<span class="boring">}</span></code></pre></pre>
<h3 id="issue-2-poor-performance-with-small-chunks"><a class="header" href="#issue-2-poor-performance-with-small-chunks">Issue 2: Poor Performance with Small Chunks</a></h3>
<p><strong>Symptom:</strong> Processing is slower than expected.</p>
<p><strong>Diagnosis:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let start = Instant::now();
let chunks = chunk_file(path, chunk_size)?;
let duration = start.elapsed();

println!("Chunking took: {:?}", duration);
println!("Chunks created: {}", chunks.len());
println!("Avg per chunk: {:?}", duration / chunks.len() as u32);
<span class="boring">}</span></code></pre></pre>
<p><strong>Solutions:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// 1. Use optimal chunk size
let chunk_size = ChunkSize::optimal_for_file_size(file_size);

// 2. Increase chunk size
let larger = ChunkSize::from_mb(16)?;  // Instead of 1 MB

// 3. Benchmark different sizes
let results = benchmark_chunk_sizes(path, &amp;sizes).await;
let (best_size, _) = results.first().unwrap();
<span class="boring">}</span></code></pre></pre>
<h3 id="issue-3-too-many-chunks"><a class="header" href="#issue-3-too-many-chunks">Issue 3: Too Many Chunks</a></h3>
<p><strong>Symptom:</strong></p>
<pre><code class="language-text">Created 10,000 chunks for 1 GB file
</code></pre>
<p><strong>Solutions:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// 1. Increase chunk size
let chunk_size = ChunkSize::from_mb(16)?;  // ~63 chunks for 1 GB

// 2. Use optimal sizing
let chunk_size = ChunkSize::optimal_for_file_size(file_size);

// 3. Set maximum chunk count
let max_chunks = 100;
let min_chunk_size = file_size / max_chunks as u64;
let chunk_size = ChunkSize::new(min_chunk_size as usize)?;
<span class="boring">}</span></code></pre></pre>
<h3 id="issue-4-chunk-size-larger-than-file"><a class="header" href="#issue-4-chunk-size-larger-than-file">Issue 4: Chunk Size Larger Than File</a></h3>
<p><strong>Symptom:</strong></p>
<pre><code class="language-text">Error: Chunk size 16 MB is larger than file size (1 MB)
</code></pre>
<p><strong>Solutions:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// 1. Validate before chunking
let chunk_size = if file_size &lt; chunk_size.bytes() as u64 {
    ChunkSize::new(file_size as usize)?
} else {
    chunk_size
};

// 2. Use validate_user_input
match ChunkSize::validate_user_input(user_size_mb, file_size) {
    Ok(bytes) =&gt; ChunkSize::new(bytes)?,
    Err(msg) =&gt; {
        eprintln!("Warning: {}", msg);
        ChunkSize::optimal_for_file_size(file_size)
    },
}
<span class="boring">}</span></code></pre></pre>
<hr />
<h2 id="testing-strategies"><a class="header" href="#testing-strategies">Testing Strategies</a></h2>
<h3 id="unit-tests"><a class="header" href="#unit-tests">Unit Tests</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_chunk_size_validation() {
        // Valid sizes
        assert!(ChunkSize::new(1024).is_ok());
        assert!(ChunkSize::new(1024 * 1024).is_ok());

        // Invalid sizes
        assert!(ChunkSize::new(0).is_err());
        assert!(ChunkSize::new(600 * 1024 * 1024).is_err());
    }

    #[test]
    fn test_optimal_sizing() {
        // Small file
        let small = ChunkSize::optimal_for_file_size(500_000);
        assert_eq!(small.bytes(), 64 * 1024);

        // Medium file
        let medium = ChunkSize::optimal_for_file_size(100 * 1024 * 1024);
        assert_eq!(medium.bytes(), 16 * 1024 * 1024);

        // Large file
        let large = ChunkSize::optimal_for_file_size(1_000_000_000);
        assert_eq!(large.bytes(), 64 * 1024 * 1024);
    }

    #[test]
    fn test_chunks_needed() {
        let chunk_size = ChunkSize::from_mb(4).unwrap();
        let file_size = 100 * 1024 * 1024;  // 100 MB

        let num_chunks = chunk_size.chunks_needed_for_file(file_size);
        assert_eq!(num_chunks, 25);  // 100 MB / 4 MB = 25
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="integration-tests"><a class="header" href="#integration-tests">Integration Tests</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[tokio::test]
async fn test_file_chunking() {
    // Create test file
    let test_file = create_test_file(10 * 1024 * 1024);  // 10 MB

    // Chunk the file
    let chunk_size = ChunkSize::from_mb(1).unwrap();
    let chunks = chunk_file(&amp;test_file, chunk_size).unwrap();

    assert_eq!(chunks.len(), 10);

    // Verify sequences
    for (i, chunk) in chunks.iter().enumerate() {
        assert_eq!(chunk.sequence_number(), i as u64);
    }

    // Verify last chunk flag
    assert!(chunks.last().unwrap().is_final());
}
<span class="boring">}</span></code></pre></pre>
<h3 id="performance-tests"><a class="header" href="#performance-tests">Performance Tests</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[tokio::test]
async fn test_chunking_performance() {
    let test_file = create_test_file(100 * 1024 * 1024);  // 100 MB

    let sizes = vec![
        ChunkSize::from_mb(1).unwrap(),
        ChunkSize::from_mb(16).unwrap(),
        ChunkSize::from_mb(64).unwrap(),
    ];

    for size in sizes {
        let start = Instant::now();
        let chunks = chunk_file(&amp;test_file, size).unwrap();
        let duration = start.elapsed();

        println!("{} MB chunks: {} chunks in {:?}",
            size.megabytes(), chunks.len(), duration);
    }
}
<span class="boring">}</span></code></pre></pre>
<hr />
<h2 id="next-steps"><a class="header" href="#next-steps">Next Steps</a></h2>
<p>After understanding chunking strategy, explore related topics:</p>
<h3 id="related-implementation-topics"><a class="header" href="#related-implementation-topics">Related Implementation Topics</a></h3>
<ol>
<li><strong><a href="file-io.html">File I/O</a></strong>: File reading and writing with chunks</li>
<li><strong><a href="binary-format.html">Binary Format</a></strong>: How chunks are serialized</li>
</ol>
<h3 id="related-topics"><a class="header" href="#related-topics">Related Topics</a></h3>
<ul>
<li><strong><a href="stages.html">Stage Processing</a></strong>: How stages process chunks</li>
<li><strong><a href="compression.html">Compression</a></strong>: Compressing chunk data</li>
<li><strong><a href="encryption.html">Encryption</a></strong>: Encrypting chunks</li>
</ul>
<h3 id="advanced-topics"><a class="header" href="#advanced-topics">Advanced Topics</a></h3>
<ul>
<li><strong><a href="../advanced/performance.html">Performance Optimization</a></strong>: Optimizing chunking performance</li>
<li><strong><a href="../advanced/concurrency.html">Concurrency Model</a></strong>: Parallel chunk processing</li>
</ul>
<hr />
<h2 id="summary"><a class="header" href="#summary">Summary</a></h2>
<p><strong>Key Takeaways:</strong></p>
<ol>
<li><strong>Chunking</strong> divides files into manageable pieces for efficient processing</li>
<li><strong>Chunk sizes</strong> range from 1 byte to 512 MB with optimal sizes empirically determined</li>
<li><strong>Optimal sizing</strong> adapts to file size: small files use small chunks, large files use large chunks</li>
<li><strong>Memory management</strong> ensures bounded memory usage regardless of file size</li>
<li><strong>Parallel processing</strong> enables concurrent chunk processing for better performance</li>
<li><strong>Adaptive chunking</strong> can dynamically adjust chunk sizes based on performance</li>
<li><strong>Performance</strong> varies significantly with chunk size (64 KB: ~40 MB/s, 128 MB: ~350 MB/s)</li>
</ol>
<p><strong>Architecture File References:</strong></p>
<ul>
<li><strong>ChunkSize:</strong> <code>pipeline-domain/src/value_objects/chunk_size.rs:169</code></li>
<li><strong>FileChunk:</strong> <code>pipeline-domain/src/value_objects/file_chunk.rs:176</code></li>
<li><strong>Chunking Diagram:</strong> <code>pipeline/docs/diagrams/chunk-processing.puml</code></li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../implementation/file-io.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next prefetch" href="../implementation/binary-format.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../implementation/file-io.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next prefetch" href="../implementation/binary-format.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="../elasticlunr.min.js"></script>
        <script src="../mark.min.js"></script>
        <script src="../searcher.js"></script>

        <script src="../clipboard.min.js"></script>
        <script src="../highlight.js"></script>
        <script src="../book.js"></script>

        <!-- Custom JS scripts -->



    </div>
    </body>
</html>
