// /////////////////////////////////////////////////////////////////////////////
// Adaptive Pipeline
// Copyright (c) 2025 Michael Gardner, A Bit of Help, Inc.
// SPDX-License-Identifier: BSD-3-Clause
// See LICENSE file in the project root.
// /////////////////////////////////////////////////////////////////////////////


//! # ID Generator Demo - Database Initialization Utility
//!
//! This comprehensive example demonstrates the proper generation and usage of
//! ULID-based identifiers in the adaptive pipeline system. It serves as both a
//! demonstration of the ID generation system and a practical utility for
//! database initialization.
//!
//! ## Overview
//!
//! The ID generator demo provides:
//!
//! - **ULID Generation**: Proper ULID-based identifier generation using domain
//!   value objects
//! - **Database Initialization**: Creates fresh database with correctly
//!   formatted IDs
//! - **SQL Script Generation**: Generates SQL scripts for database setup
//! - **ID Validation**: Validates generated IDs against domain constraints
//! - **Test Data Creation**: Creates realistic test data for development and
//!   testing
//!
//! ## Architecture
//!
//! The demo follows Domain-Driven Design principles for ID generation:
//!
//! ```text
//! â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
//! â”‚                    ID Generation System                            â”‚
//! â”‚                                                                     â”‚
//! â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
//! â”‚  â”‚                Domain Value Objects                     â”‚    â”‚
//! â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚    â”‚
//! â”‚  â”‚  â”‚ PipelineId  â”‚ â”‚   StageId   â”‚ â”‚   ProcessId     â”‚    â”‚    â”‚
//! â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚    â”‚
//! â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
//! â”‚                            â”‚                                     â”‚
//! â”‚                            â–¼                                     â”‚
//! â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
//! â”‚  â”‚                 ULID Generator                          â”‚    â”‚
//! â”‚  â”‚  - Monotonic ordering                                   â”‚    â”‚
//! â”‚  â”‚  - Timestamp-based                                      â”‚    â”‚
//! â”‚  â”‚  - Cryptographically secure                            â”‚    â”‚
//! â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
//! â”‚                            â”‚                                     â”‚
//! â”‚                            â–¼                                     â”‚
//! â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
//! â”‚  â”‚              Database Initialization                   â”‚    â”‚
//! â”‚  â”‚  - SQL script generation                                â”‚    â”‚
//! â”‚  â”‚  - Test data creation                                   â”‚    â”‚
//! â”‚  â”‚  - Schema validation                                    â”‚    â”‚
//! â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
//! â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
//! ```
//!
//! ## ULID Properties
//!
//! ### Universally Unique Lexicographically Sortable Identifier
//!
//! ULIDs provide several advantages over traditional UUIDs:
//!
//! - **Lexicographic Sorting**: Natural ordering based on generation time
//! - **Monotonic Ordering**: Guaranteed ordering within the same millisecond
//! - **Compact Representation**: 26-character string representation
//! - **Timestamp Component**: Embedded timestamp for temporal ordering
//! - **Randomness**: Cryptographically secure random component
//!
//! ### ULID Structure
//!
//! ```text
//! 01AN4Z07BY      79KA1307SR9X4MV3
//! |----------|    |----------------|
//!  Timestamp          Randomness
//!   48bits             80bits
//! ```
//!
//! ## Features Demonstrated
//!
//! ### Domain Value Objects
//!
//! The demo showcases proper usage of domain value objects:
//!
//! ```rust
//! use pipeline_domain::value_objects::{PipelineId, StageId};
//!
//! // Generate type-safe pipeline ID
//! let pipeline_id = PipelineId::new();
//! println!("Pipeline ID: {}", pipeline_id);
//!
//! // Generate stage ID with validation
//! let stage_id = StageId::new();
//! println!("Stage ID: {}", stage_id);
//! ```
//!
//! ### ID Generation Patterns
//!
//! ```rust
//! // Batch ID generation for related entities
//! struct GeneratedIds {
//!     pipeline_id: PipelineId,
//!     stage_ids: Vec<StageId>,
//!     process_ids: Vec<ProcessId>,
//! }
//!
//! fn generate_related_ids() -> GeneratedIds {
//!     GeneratedIds {
//!         pipeline_id: PipelineId::new(),
//!         stage_ids: (0..5).map(|_| StageId::new()).collect(),
//!         process_ids: (0..10).map(|_| ProcessId::new()).collect(),
//!     }
//! }
//! ```
//!
//! ### Database Integration
//!
//! ```rust
//! // Generate SQL script with proper ID formatting
//! fn generate_sql_script(ids: &GeneratedIds) -> String {
//!     format!(
//!         r#"
//!         INSERT INTO pipelines (id, name, created_at) VALUES
//!         ('{}', 'Test Pipeline', datetime('now'));
//!         
//!         INSERT INTO stages (id, pipeline_id, name, order_index) VALUES
//!         ('{}', '{}', 'Compression Stage', 0);
//!         "#,
//!         ids.pipeline_id, ids.compression_stage, ids.pipeline_id
//!     )
//! }
//! ```
//!
//! ## Usage Examples
//!
//! ### Basic ID Generation
//!
//! ```rust
//! use pipeline_domain::value_objects::PipelineId;
//!
//! // Generate a new pipeline ID
//! let pipeline_id = PipelineId::new();
//! println!("Generated Pipeline ID: {}", pipeline_id);
//!
//! // IDs are lexicographically sortable
//! let id1 = PipelineId::new();
//! let id2 = PipelineId::new();
//! assert!(id1 < id2); // Later IDs are lexicographically greater
//! ```
//!
//! ### Batch Generation for Related Entities
//!
//! ```rust
//! // Generate IDs for a complete pipeline with stages
//! let pipeline_id = PipelineId::new();
//! let stage_ids: Vec<StageId> = (0..3).map(|_| StageId::new()).collect();
//!
//! println!("Pipeline: {}", pipeline_id);
//! for (i, stage_id) in stage_ids.iter().enumerate() {
//!     println!("  Stage {}: {}", i + 1, stage_id);
//! }
//! ```
//!
//! ### Database Initialization
//!
//! ```rust
//! // Create test data with proper IDs
//! let ids = generate_all_ids();
//! let sql_script = generate_sql_script(&ids);
//!
//! // Write to file for database initialization
//! std::fs::write("test_data.sql", sql_script)?;
//! ```
//!
//! ## Running the Demo
//!
//! Execute the ID generator demo:
//!
//! ```bash
//! cargo run --example id_generator_demo
//! ```
//!
//! ### Expected Output
//!
//! The demo will display:
//!
//! ```text
//! ğŸ†” ID Generator - Creating fresh database with proper ULIDs
//! ============================================================
//!
//! Generated IDs:
//! Pipeline IDs:
//!   test-multi-stage: 01HK8XVJQ2M7N3P4R5S6T7U8V9
//!   image-processing: 01HK8XVJQ3A1B2C3D4E5F6G7H8
//!
//! Stage IDs:
//!   input-checksum: 01HK8XVJQ4I9J0K1L2M3N4O5P6
//!   compression: 01HK8XVJQ5Q7R8S9T0U1V2W3X4
//!   encryption: 01HK8XVJQ6Y5Z6A7B8C9D0E1F2
//!
//! âœ… SUCCESS: Generated fresh database script
//! ğŸ“„ File: scripts/test_data/fresh_database.sql
//! ğŸ¯ Ready to create database with: sqlite3 scripts/test_data/structured_pipeline.db < scripts/test_data/fresh_database.sql
//! ```
//!
//! ## Generated SQL Script
//!
//! The demo generates a complete SQL script for database initialization:
//!
//! ```sql
//! -- Pipeline table initialization
//! INSERT INTO pipelines (id, name, description, created_at) VALUES
//! ('01HK8XVJQ2M7N3P4R5S6T7U8V9', 'Test Multi-Stage Pipeline', 'Demo pipeline with multiple stages', datetime('now')),
//! ('01HK8XVJQ3A1B2C3D4E5F6G7H8', 'Image Processing Pipeline', 'Image processing and optimization', datetime('now'));
//!
//! -- Stage table initialization
//! INSERT INTO stages (id, pipeline_id, name, stage_type, order_index, created_at) VALUES
//! ('01HK8XVJQ4I9J0K1L2M3N4O5P6', '01HK8XVJQ2M7N3P4R5S6T7U8V9', 'Input Checksum', 'checksum', 0, datetime('now')),
//! ('01HK8XVJQ5Q7R8S9T0U1V2W3X4', '01HK8XVJQ2M7N3P4R5S6T7U8V9', 'Compression', 'compression', 1, datetime('now')),
//! ('01HK8XVJQ6Y5Z6A7B8C9D0E1F2', '01HK8XVJQ2M7N3P4R5S6T7U8V9', 'Encryption', 'encryption', 2, datetime('now'));
//! ```
//!
//! ## ID Validation
//!
//! The demo includes comprehensive ID validation:
//!
//! ```rust
//! fn validate_generated_ids(ids: &GeneratedIds) -> Result<(), ValidationError> {
//!     // Validate pipeline IDs
//!     for pipeline_id in &ids.pipeline_ids {
//!         if !pipeline_id.is_valid() {
//!             return Err(ValidationError::InvalidPipelineId(pipeline_id.clone()));
//!         }
//!     }
//!
//!     // Validate stage IDs
//!     for stage_id in &ids.stage_ids {
//!         if !stage_id.is_valid() {
//!             return Err(ValidationError::InvalidStageId(stage_id.clone()));
//!         }
//!     }
//!
//!     // Validate uniqueness
//!     let all_ids: Vec<String> = ids.all_ids().map(|id| id.to_string()).collect();
//!     let unique_ids: std::collections::HashSet<String> = all_ids.iter().cloned().collect();
//!
//!     if all_ids.len() != unique_ids.len() {
//!         return Err(ValidationError::DuplicateIds);
//!     }
//!
//!     Ok(())
//! }
//! ```
//!
//! ## Database Integration
//!
//! ### Schema Compatibility
//!
//! The generated IDs are compatible with the database schema:
//!
//! ```sql
//! CREATE TABLE pipelines (
//!     id TEXT PRIMARY KEY,           -- ULID as TEXT
//!     name TEXT NOT NULL,
//!     description TEXT,
//!     created_at DATETIME DEFAULT CURRENT_TIMESTAMP
//! );
//!
//! CREATE TABLE stages (
//!     id TEXT PRIMARY KEY,           -- ULID as TEXT
//!     pipeline_id TEXT NOT NULL,    -- Foreign key to pipelines.id
//!     name TEXT NOT NULL,
//!     stage_type TEXT NOT NULL,
//!     order_index INTEGER NOT NULL,
//!     created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
//!     FOREIGN KEY (pipeline_id) REFERENCES pipelines(id)
//! );
//! ```
//!
//! ### Index Optimization
//!
//! ULIDs provide natural indexing advantages:
//!
//! ```sql
//! -- Primary key index is automatically created and optimized
//! -- ULIDs sort naturally by creation time
//! CREATE INDEX idx_pipelines_created_at ON pipelines(created_at);
//! CREATE INDEX idx_stages_pipeline_id ON stages(pipeline_id);
//! CREATE INDEX idx_stages_order ON stages(pipeline_id, order_index);
//! ```
//!
//! ## Performance Characteristics
//!
//! ### ID Generation Performance
//!
//! - **Generation Speed**: ~1M IDs per second on modern hardware
//! - **Memory Usage**: Minimal memory footprint per ID
//! - **Collision Probability**: Negligible (2^-80 for random component)
//!
//! ### Database Performance
//!
//! - **Insert Performance**: Excellent due to monotonic ordering
//! - **Query Performance**: Fast range queries using lexicographic ordering
//! - **Index Efficiency**: Optimal B-tree performance
//!
//! ## Testing Integration
//!
//! The demo supports comprehensive testing:
//!
//! ```rust
//! #[cfg(test)]
//! mod tests {
//!     use super::*;
//!
//!     #[test]
//!     fn test_id_generation() {
//!         let id1 = PipelineId::new();
//!         let id2 = PipelineId::new();
//!
//!         // IDs should be unique
//!         assert_ne!(id1, id2);
//!
//!         // Later IDs should be lexicographically greater
//!         assert!(id1 < id2);
//!     }
//!
//!     #[test]
//!     fn test_batch_generation() {
//!         let ids = generate_all_ids();
//!
//!         // Validate all generated IDs
//!         validate_generated_ids(&ids).unwrap();
//!
//!         // Ensure uniqueness
//!         let all_ids: Vec<String> = ids.all_ids().map(|id| id.to_string()).collect();
//!         let unique_ids: std::collections::HashSet<String> = all_ids.iter().cloned().collect();
//!         assert_eq!(all_ids.len(), unique_ids.len());
//!     }
//!
//!     #[test]
//!     fn test_sql_generation() {
//!         let ids = generate_all_ids();
//!         let sql = generate_sql_script(&ids);
//!
//!         // SQL should contain all generated IDs
//!         for id in ids.all_ids() {
//!             assert!(sql.contains(&id.to_string()));
//!         }
//!     }
//! }
//! ```
//!
//! ## Security Considerations
//!
//! - **Cryptographic Security**: Random component uses cryptographically secure
//!   RNG
//! - **Unpredictability**: Random component prevents ID prediction
//! - **No Information Leakage**: IDs don't reveal sensitive information
//! - **Collision Resistance**: Extremely low probability of collisions
//!
//! ## Best Practices Demonstrated
//!
//! - **Type Safety**: Use domain value objects for type-safe ID handling
//! - **Validation**: Validate IDs at generation and usage points
//! - **Batch Generation**: Generate related IDs together for consistency
//! - **Database Integration**: Proper SQL script generation for initialization
//! - **Testing**: Comprehensive testing of ID generation and validation
//! - **Documentation**: Clear documentation of ID structure and usage
//!
//! ## Learning Outcomes
//!
//! After running this demo, you will understand:
//!
//! - How to generate and use ULIDs in domain-driven design
//! - Proper ID validation and error handling
//! - Database initialization with generated IDs
//! - Performance characteristics of ULID-based systems
//! - Testing strategies for ID generation systems
//! - Security considerations for identifier systems

use adaptive_pipeline_domain::entities::pipeline_stage::{StageConfiguration, StageType};
use adaptive_pipeline_domain::value_objects::{PipelineId, StageId};
use adaptive_pipeline_domain::{Pipeline, PipelineStage};
use std::collections::HashMap;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ†” ID Generator - Creating fresh database with proper ULIDs");
    println!("{}", "=".repeat(60));

    // Generate all IDs using our value objects
    let ids = generate_all_ids();

    // Display generated IDs
    display_ids(&ids);

    // Create and validate pipeline objects
    let pipeline = create_test_pipeline()?;
    validate_pipeline(&pipeline);

    // Generate SQL script
    let sql_script = generate_sql_script(&ids);

    // Write to file
    let output_path = "scripts/test_data/fresh_database.sql";
    std::fs::write(output_path, sql_script)?;

    println!("\nâœ… SUCCESS: Generated fresh database script");
    println!("ğŸ“„ File: {}", output_path);
    println!(
        "ğŸ¯ Ready to create database with: sqlite3 scripts/test_data/structured_pipeline.db < {}",
        output_path
    );

    Ok(())
}

struct GeneratedIds {
    // Pipeline IDs
    test_multi_stage: PipelineId,
    image_processing: PipelineId,

    // Stage IDs for test-multi-stage
    input_checksum: StageId,
    compression: StageId,
    encryption: StageId,
    output_checksum: StageId,

    // Stage IDs for image-processing
    input_validation: StageId,
    image_compression: StageId,
}

fn generate_all_ids() -> GeneratedIds {
    GeneratedIds {
        // Pipeline IDs
        test_multi_stage: PipelineId::new(),
        image_processing: PipelineId::new(),

        // Stage IDs for test-multi-stage
        input_checksum: StageId::new(),
        compression: StageId::new(),
        encryption: StageId::new(),
        output_checksum: StageId::new(),

        // Stage IDs for image-processing
        input_validation: StageId::new(),
        image_compression: StageId::new(),
    }
}

fn display_ids(ids: &GeneratedIds) {
    println!("\nğŸ“‹ Generated Pipeline IDs:");
    println!("  test-multi-stage: {}", ids.test_multi_stage);
    println!("  image-processing: {}", ids.image_processing);

    println!("\nğŸ”§ Generated Stage IDs for test-multi-stage:");
    println!("  input_checksum:   {}", ids.input_checksum);
    println!("  compression:      {}", ids.compression);
    println!("  encryption:       {}", ids.encryption);
    println!("  output_checksum:  {}", ids.output_checksum);

    println!("\nğŸ”§ Generated Stage IDs for image-processing:");
    println!("  input_validation:  {}", ids.input_validation);
    println!("  image_compression: {}", ids.image_compression);
}

fn create_test_pipeline() -> Result<Pipeline, Box<dyn std::error::Error>> {
    let mut user_stages = Vec::new();

    // Create user-defined stages (Pipeline::new will add checksum stages
    // automatically)
    let compression_stage = PipelineStage::new(
        "compression".to_string(),
        StageType::Compression,
        StageConfiguration::new("brotli".to_string(), HashMap::new(), false),
        1, // Order will be adjusted by Pipeline::new
    )?;

    let encryption_stage = PipelineStage::new(
        "encryption".to_string(),
        StageType::Encryption,
        StageConfiguration::new("aes256gcm".to_string(), HashMap::new(), false),
        2, // Order will be adjusted by Pipeline::new
    )?;

    user_stages.push(compression_stage);
    user_stages.push(encryption_stage);

    // Create pipeline (automatically adds input_checksum and output_checksum)
    let pipeline = Pipeline::new("test-multi-stage".to_string(), user_stages)?;

    Ok(pipeline)
}

fn validate_pipeline(pipeline: &Pipeline) {
    println!("\nâœ… Validated test-multi-stage pipeline:");
    println!("  Name: {}", pipeline.name());
    println!(
        "  Stages: {} (including automatic checksum stages)",
        pipeline.stages().len()
    );

    for (i, stage) in pipeline.stages().iter().enumerate() {
        println!(
            "    {}. {} (type: {}, order: {})",
            i,
            stage.name(),
            stage.stage_type(),
            stage.order()
        );
    }
}

fn generate_sql_script(ids: &GeneratedIds) -> String {
    format!(
        r#"-- Generated by ID Generator - SOURCE OF TRUTH for Database
-- This script creates a fresh database with proper ULID format IDs
-- Generated at: {}

-- Clean slate - drop all tables
DROP TABLE IF EXISTS stage_parameters;
DROP TABLE IF EXISTS pipeline_stages;
DROP TABLE IF EXISTS pipeline_configuration;
DROP TABLE IF EXISTS processing_metrics;
DROP TABLE IF EXISTS processing_sessions;
DROP TABLE IF EXISTS file_chunks;
DROP TABLE IF EXISTS security_contexts;
DROP TABLE IF EXISTS pipelines;

-- Create schema
CREATE TABLE pipelines (
    id TEXT PRIMARY KEY,
    name TEXT NOT NULL UNIQUE,
    archived BOOLEAN NOT NULL DEFAULT FALSE,
    created_at TEXT NOT NULL,
    updated_at TEXT NOT NULL
);

CREATE TABLE pipeline_configuration (
    pipeline_id TEXT NOT NULL,
    key TEXT NOT NULL,
    value TEXT NOT NULL,
    PRIMARY KEY (pipeline_id, key),
    FOREIGN KEY (pipeline_id) REFERENCES pipelines(id)
);

CREATE TABLE pipeline_stages (
    id TEXT PRIMARY KEY,
    pipeline_id TEXT NOT NULL,
    name TEXT NOT NULL,
    stage_type TEXT NOT NULL,
    enabled BOOLEAN NOT NULL DEFAULT TRUE,
    stage_order INTEGER NOT NULL,
    algorithm TEXT NOT NULL,
    parallel_processing BOOLEAN NOT NULL DEFAULT FALSE,
    chunk_size INTEGER,
    created_at TEXT NOT NULL,
    updated_at TEXT NOT NULL,
    FOREIGN KEY (pipeline_id) REFERENCES pipelines(id)
);

CREATE TABLE stage_parameters (
    stage_id TEXT NOT NULL,
    key TEXT NOT NULL,
    value TEXT NOT NULL,
    PRIMARY KEY (stage_id, key),
    FOREIGN KEY (stage_id) REFERENCES pipeline_stages(id)
);

CREATE TABLE processing_metrics (
    pipeline_id TEXT PRIMARY KEY,
    bytes_processed INTEGER NOT NULL DEFAULT 0,
    bytes_total INTEGER NOT NULL DEFAULT 0,
    chunks_processed INTEGER NOT NULL DEFAULT 0,
    chunks_total INTEGER NOT NULL DEFAULT 0,
    start_time_rfc3339 TEXT,
    end_time_rfc3339 TEXT,
    processing_duration_ms INTEGER,
    throughput_bytes_per_second REAL NOT NULL DEFAULT 0.0,
    compression_ratio REAL,
    error_count INTEGER NOT NULL DEFAULT 0,
    warning_count INTEGER NOT NULL DEFAULT 0,
    input_file_size_bytes INTEGER NOT NULL DEFAULT 0,
    output_file_size_bytes INTEGER NOT NULL DEFAULT 0,
    input_file_checksum TEXT,
    output_file_checksum TEXT,
    FOREIGN KEY (pipeline_id) REFERENCES pipelines(id)
);

-- Insert pipelines with proper ULID format
INSERT INTO pipelines (id, name, archived, created_at, updated_at) VALUES
('{}', 'test-multi-stage', false, '2025-07-09T19:28:00Z', '2025-07-09T19:28:00Z'),
('{}', 'image-processing', false, '2025-07-09T19:28:00Z', '2025-07-09T19:28:00Z');

-- Insert pipeline configuration
INSERT INTO pipeline_configuration (pipeline_id, key, value) VALUES
('{}', 'encryption_algorithm', 'aes256gcm'),
('{}', 'compression_algorithm', 'brotli'),
('{}', 'chunk_size_mb', '1'),
('{}', 'max_file_size', '100MB'),
('{}', 'output_format', 'JPEG'),
('{}', 'quality', '85');

-- Insert pipeline stages (4 stages for test-multi-stage, 2 for image-processing)
INSERT INTO pipeline_stages (id, pipeline_id, name, stage_type, enabled, stage_order, algorithm, parallel_processing, chunk_size, created_at, updated_at) VALUES
-- test-multi-stage stages (4 total)
('{}', '{}', 'input_checksum', 'Custom', true, 0, 'sha256', false, null, '2025-07-09T19:28:00Z', '2025-07-09T19:28:00Z'),
('{}', '{}', 'compression', 'Custom', true, 1, 'brotli', false, null, '2025-07-09T19:28:00Z', '2025-07-09T19:28:00Z'),
('{}', '{}', 'encryption', 'Custom', true, 2, 'aes256gcm', false, null, '2025-07-09T19:28:00Z', '2025-07-09T19:28:00Z'),
('{}', '{}', 'output_checksum', 'Custom', true, 3, 'sha256', false, null, '2025-07-09T19:28:00Z', '2025-07-09T19:28:00Z'),
-- image-processing stages (2 total)
('{}', '{}', 'input_validation', 'Custom', true, 0, 'sha256', false, null, '2025-07-09T19:28:00Z', '2025-07-09T19:28:00Z'),
('{}', '{}', 'image_compression', 'Custom', true, 1, 'jpeg', false, null, '2025-07-09T19:28:00Z', '2025-07-09T19:28:00Z');

-- Insert stage parameters
INSERT INTO stage_parameters (stage_id, key, value) VALUES
('{}', 'level', '6'),
('{}', 'compression_level', '6');

-- Insert processing metrics (initialized to zero)
INSERT INTO processing_metrics (pipeline_id) VALUES
('{}'),
('{}');

-- Verification query
SELECT 'pipelines' as table_name, COUNT(*) as count FROM pipelines
UNION ALL
SELECT 'pipeline_configuration', COUNT(*) FROM pipeline_configuration
UNION ALL
SELECT 'pipeline_stages', COUNT(*) FROM pipeline_stages
UNION ALL
SELECT 'stage_parameters', COUNT(*) FROM stage_parameters
UNION ALL
SELECT 'processing_metrics', COUNT(*) FROM processing_metrics;

-- Success message
SELECT 'Database created successfully with proper ULID format!' as status;
"#,
        chrono::Utc::now().format("%Y-%m-%d %H:%M:%S UTC"),
        // Pipeline IDs
        ids.test_multi_stage,
        ids.image_processing,
        // Configuration
        ids.test_multi_stage,
        ids.test_multi_stage,
        ids.test_multi_stage,
        ids.image_processing,
        ids.image_processing,
        ids.image_processing,
        // Stages
        ids.input_checksum,
        ids.test_multi_stage,
        ids.compression,
        ids.test_multi_stage,
        ids.encryption,
        ids.test_multi_stage,
        ids.output_checksum,
        ids.test_multi_stage,
        ids.input_validation,
        ids.image_processing,
        ids.image_compression,
        ids.image_processing,
        // Parameters
        ids.compression,
        ids.image_compression,
        // Metrics
        ids.test_multi_stage,
        ids.image_processing
    )
}
