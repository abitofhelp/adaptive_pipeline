<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Benchmarking - Pipeline Developer Guide</title>


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        <link rel="stylesheet" href="../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="../highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="../tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "../";
            const default_light_theme = "light";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "../searchindex.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="../toc.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="../toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Pipeline Developer Guide</h1>

                    <div class="right-buttons">
                        <a href="../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <i class="fa fa-spinner fa-spin"></i>
                            </div>
                        </div>
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="benchmarking"><a class="header" href="#benchmarking">Benchmarking</a></h1>
<p><strong>Version:</strong> 0.1.0
<strong>Date:</strong> 2025-01-04
<strong>SPDX-License-Identifier:</strong> BSD-3-Clause
<strong>License File:</strong> See the LICENSE file in the project root.
<strong>Copyright:</strong> © 2025 Michael Gardner, A Bit of Help, Inc.
<strong>Authors:</strong> Michael Gardner
<strong>Status:</strong> Draft</p>
<p>This chapter covers the pipeline's benchmark suite, methodologies for measuring performance, and techniques for interpreting benchmark results to guide optimization decisions.</p>
<h2 id="overview"><a class="header" href="#overview">Overview</a></h2>
<p>The pipeline uses <a href="https://github.com/bheisler/criterion.rs">Criterion.rs</a> for rigorous, statistical benchmarking. Criterion provides:</p>
<ul>
<li><strong>Statistical Analysis</strong>: Measures mean, standard deviation, and percentiles</li>
<li><strong>Regression Detection</strong>: Identifies performance regressions automatically</li>
<li><strong>HTML Reports</strong>: Generates detailed visualizations and comparisons</li>
<li><strong>Outlier Detection</strong>: Filters statistical outliers for consistent results</li>
<li><strong>Iterative Measurement</strong>: Automatically determines iteration counts</li>
</ul>
<p><strong>Benchmark Location:</strong> <code>pipeline/benches/file_io_benchmark.rs</code></p>
<h2 id="benchmark-suite"><a class="header" href="#benchmark-suite">Benchmark Suite</a></h2>
<p>The benchmark suite covers four main categories:</p>
<h3 id="1-read-method-benchmarks"><a class="header" href="#1-read-method-benchmarks">1. Read Method Benchmarks</a></h3>
<p><strong>Purpose</strong>: Compare regular file I/O vs memory-mapped I/O across different file sizes.</p>
<p><strong>File Sizes Tested:</strong></p>
<ul>
<li>1 MB (small files)</li>
<li>10 MB (medium files)</li>
<li>50 MB (large files)</li>
<li>100 MB (very large files)</li>
</ul>
<p><strong>Methods Compared:</strong></p>
<ul>
<li><code>regular_io</code>: Traditional buffered file reading</li>
<li><code>memory_mapped</code>: Memory-mapped file access (mmap)</li>
</ul>
<p><strong>Configuration:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let service = TokioFileIO::new(FileIOConfig {
    default_chunk_size: 64 * 1024,     // 64KB chunks
    max_mmap_size: 1024 * 1024 * 1024, // 1GB threshold
    enable_memory_mapping: true,
    ..Default::default()
});
<span class="boring">}</span></code></pre></pre>
<p><strong>Expected Results:</strong></p>
<ul>
<li><strong>Small files (&lt; 10 MB)</strong>: Regular I/O faster (lower setup cost)</li>
<li><strong>Large files (&gt; 50 MB)</strong>: Memory mapping faster (reduced copying)</li>
</ul>
<h3 id="2-chunk-size-benchmarks"><a class="header" href="#2-chunk-size-benchmarks">2. Chunk Size Benchmarks</a></h3>
<p><strong>Purpose</strong>: Determine optimal chunk sizes for different workloads.</p>
<p><strong>Chunk Sizes Tested:</strong></p>
<ul>
<li>4 KB (4096 bytes)</li>
<li>8 KB (8192 bytes)</li>
<li>16 KB (16384 bytes)</li>
<li>32 KB (32768 bytes)</li>
<li>64 KB (65536 bytes)</li>
<li>128 KB (131072 bytes)</li>
</ul>
<p><strong>File Size:</strong> 10 MB (representative medium file)</p>
<p><strong>Methods:</strong></p>
<ul>
<li><code>regular_io</code>: Chunked reading with various sizes</li>
<li><code>memory_mapped</code>: Memory mapping with logical chunk sizes</li>
</ul>
<p><strong>Expected Results:</strong></p>
<ul>
<li><strong>Smaller chunks (4-16 KB)</strong>: Higher overhead, more syscalls</li>
<li><strong>Medium chunks (32-64 KB)</strong>: Good balance for most workloads</li>
<li><strong>Larger chunks (128 KB+)</strong>: Lower syscall overhead, higher memory usage</li>
</ul>
<h3 id="3-checksum-calculation-benchmarks"><a class="header" href="#3-checksum-calculation-benchmarks">3. Checksum Calculation Benchmarks</a></h3>
<p><strong>Purpose</strong>: Measure overhead of integrity verification.</p>
<p><strong>Benchmarks:</strong></p>
<ul>
<li><code>with_checksums</code>: File reading with SHA-256 checksum calculation</li>
<li><code>without_checksums</code>: File reading without checksums</li>
<li><code>checksum_only</code>: Standalone checksum calculation</li>
</ul>
<p><strong>File Size:</strong> 10 MB</p>
<p><strong>Expected Results:</strong></p>
<ul>
<li>Checksum overhead: 10-30% depending on CPU and chunk size</li>
<li>Larger chunks reduce relative overhead (fewer per-chunk hash operations)</li>
</ul>
<h3 id="4-write-operation-benchmarks"><a class="header" href="#4-write-operation-benchmarks">4. Write Operation Benchmarks</a></h3>
<p><strong>Purpose</strong>: Compare write performance across data sizes and options.</p>
<p><strong>Data Sizes Tested:</strong></p>
<ul>
<li>1 KB (tiny writes)</li>
<li>10 KB (small writes)</li>
<li>100 KB (medium writes)</li>
<li>1000 KB / 1 MB (large writes)</li>
</ul>
<p><strong>Write Options:</strong></p>
<ul>
<li><code>write_data</code>: Buffered write without checksum</li>
<li><code>write_data_with_checksum</code>: Buffered write with SHA-256 checksum</li>
<li><code>write_data_sync</code>: Buffered write with fsync</li>
</ul>
<p><strong>Expected Results:</strong></p>
<ul>
<li>Write throughput: 100-1000 MB/s (buffered, no sync)</li>
<li>Checksum overhead: 10-30%</li>
<li>Sync overhead: 10-100x depending on storage device</li>
</ul>
<h2 id="running-benchmarks"><a class="header" href="#running-benchmarks">Running Benchmarks</a></h2>
<h3 id="basic-usage"><a class="header" href="#basic-usage">Basic Usage</a></h3>
<p><strong>Run all benchmarks:</strong></p>
<pre><code class="language-bash">cargo bench --bench file_io_benchmark
</code></pre>
<p><strong>Output:</strong></p>
<pre><code class="language-text">file_read_methods/regular_io/1    time:   [523.45 µs 528.12 µs 533.28 µs]
file_read_methods/regular_io/10   time:   [5.1234 ms 5.2187 ms 5.3312 ms]
file_read_methods/memory_mapped/1 time:   [612.34 µs 618.23 µs 624.91 µs]
file_read_methods/memory_mapped/10 time: [4.8923 ms 4.9721 ms 5.0584 ms]
...
</code></pre>
<h3 id="benchmark-groups"><a class="header" href="#benchmark-groups">Benchmark Groups</a></h3>
<p><strong>Run specific benchmark group:</strong></p>
<pre><code class="language-bash"># Read methods only
cargo bench --bench file_io_benchmark -- "file_read_methods"

# Chunk sizes only
cargo bench --bench file_io_benchmark -- "chunk_sizes"

# Checksums only
cargo bench --bench file_io_benchmark -- "checksum_calculation"

# Write operations only
cargo bench --bench file_io_benchmark -- "write_operations"
</code></pre>
<h3 id="specific-benchmarks"><a class="header" href="#specific-benchmarks">Specific Benchmarks</a></h3>
<p><strong>Run benchmarks matching a pattern:</strong></p>
<pre><code class="language-bash"># All regular_io benchmarks
cargo bench --bench file_io_benchmark -- "regular_io"

# Only 50MB file benchmarks
cargo bench --bench file_io_benchmark -- "/50"

# Memory-mapped with 64KB chunks
cargo bench --bench file_io_benchmark -- "memory_mapped/64"
</code></pre>
<h3 id="output-formats"><a class="header" href="#output-formats">Output Formats</a></h3>
<p><strong>HTML report (default):</strong></p>
<pre><code class="language-bash">cargo bench --bench file_io_benchmark

# Opens: target/criterion/report/index.html
open target/criterion/report/index.html
</code></pre>
<p><strong>Save baseline for comparison:</strong></p>
<pre><code class="language-bash"># Save current performance as baseline
cargo bench --bench file_io_benchmark -- --save-baseline main

# Compare against baseline after changes
cargo bench --bench file_io_benchmark -- --baseline main
</code></pre>
<p><strong>Example comparison output:</strong></p>
<pre><code class="language-text">file_read_methods/regular_io/50
                        time:   [24.512 ms 24.789 ms 25.091 ms]
                        change: [-5.2341% -4.1234% -2.9876%] (p = 0.00 &lt; 0.05)
                        Performance has improved.
</code></pre>
<h2 id="interpreting-results"><a class="header" href="#interpreting-results">Interpreting Results</a></h2>
<h3 id="understanding-output"><a class="header" href="#understanding-output">Understanding Output</a></h3>
<p><strong>Criterion output format:</strong></p>
<pre><code class="language-text">benchmark_name          time:   [lower_bound estimate upper_bound]
                        change: [lower% estimate% upper%] (p = X.XX &lt; 0.05)
</code></pre>
<p><strong>Components:</strong></p>
<ul>
<li><strong>lower_bound</strong>: 95% confidence interval lower bound</li>
<li><strong>estimate</strong>: Best estimate (typically median)</li>
<li><strong>upper_bound</strong>: 95% confidence interval upper bound</li>
<li><strong>change</strong>: Performance change vs baseline (if available)</li>
<li><strong>p-value</strong>: Statistical significance (&lt; 0.05 = significant)</li>
</ul>
<p><strong>Example:</strong></p>
<pre><code class="language-text">file_read_methods/regular_io/50
                        time:   [24.512 ms 24.789 ms 25.091 ms]
                        change: [-5.2341% -4.1234% -2.9876%] (p = 0.00 &lt; 0.05)
</code></pre>
<p><strong>Interpretation:</strong></p>
<ul>
<li><strong>Time</strong>: File reading takes ~24.79 ms (median)</li>
<li><strong>Confidence</strong>: 95% certain actual time is between 24.51-25.09 ms</li>
<li><strong>Change</strong>: 4.12% faster than baseline (statistically significant)</li>
<li><strong>Conclusion</strong>: Performance improvement confirmed</li>
</ul>
<h3 id="throughput-calculation"><a class="header" href="#throughput-calculation">Throughput Calculation</a></h3>
<p><strong>Calculate MB/s from benchmark time:</strong></p>
<pre><code class="language-text">File size: 50 MB
Time: 24.789 ms = 0.024789 seconds

Throughput = 50 MB / 0.024789 s = 2017 MB/s
</code></pre>
<p><strong>Rust code:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let file_size_mb = 50.0;
let time_ms = 24.789;
let throughput_mb_s = file_size_mb / (time_ms / 1000.0);

println!("Throughput: {:.2} MB/s", throughput_mb_s);  // 2017 MB/s
<span class="boring">}</span></code></pre></pre>
<h3 id="regression-detection"><a class="header" href="#regression-detection">Regression Detection</a></h3>
<p><strong>Performance regression indicators:</strong></p>
<p>✅ <strong>Improvement</strong> (faster):</p>
<pre><code class="language-text">change: [-10.234% -8.123% -6.012%] (p = 0.00 &lt; 0.05)
Performance has improved.
</code></pre>
<p>❌ <strong>Regression</strong> (slower):</p>
<pre><code class="language-text">change: [+6.234% +8.456% +10.891%] (p = 0.00 &lt; 0.05)
Performance has regressed.
</code></pre>
<p>⚠️ <strong>No significant change</strong>:</p>
<pre><code class="language-text">change: [-1.234% +0.456% +2.123%] (p = 0.42 &gt; 0.05)
No change in performance detected.
</code></pre>
<p><strong>Statistical significance:</strong></p>
<ul>
<li><strong>p &lt; 0.05</strong>: Change is statistically significant (95% confidence)</li>
<li><strong>p &gt; 0.05</strong>: Change could be noise (not statistically significant)</li>
</ul>
<h3 id="html-report-navigation"><a class="header" href="#html-report-navigation">HTML Report Navigation</a></h3>
<p>Criterion generates interactive HTML reports at <code>target/criterion/report/index.html</code>.</p>
<p><strong>Report Sections:</strong></p>
<ol>
<li><strong>Summary</strong>: All benchmarks with comparisons</li>
<li><strong>Individual Reports</strong>: Detailed analysis per benchmark</li>
<li><strong>Violin Plots</strong>: Distribution visualization</li>
<li><strong>History</strong>: Performance over time</li>
</ol>
<p><strong>Key Metrics in Report:</strong></p>
<ul>
<li><strong>Mean</strong>: Average execution time</li>
<li><strong>Median</strong>: 50th percentile (typical case)</li>
<li><strong>Std Dev</strong>: Variability in measurements</li>
<li><strong>MAD</strong>: Median Absolute Deviation (robust to outliers)</li>
<li><strong>Slope</strong>: Linear regression slope (for iteration scaling)</li>
</ul>
<h2 id="performance-baselines"><a class="header" href="#performance-baselines">Performance Baselines</a></h2>
<h3 id="establishing-baselines"><a class="header" href="#establishing-baselines">Establishing Baselines</a></h3>
<p><strong>Save baseline before optimizations:</strong></p>
<pre><code class="language-bash"># 1. Run benchmarks on main branch
git checkout main
cargo bench --bench file_io_benchmark -- --save-baseline main

# 2. Switch to feature branch
git checkout feature/optimize-io

# 3. Run benchmarks and compare
cargo bench --bench file_io_benchmark -- --baseline main
</code></pre>
<p><strong>Baseline management:</strong></p>
<pre><code class="language-bash"># List all baselines
ls target/criterion/*/base/

# Delete old baseline
rm -rf target/criterion/*/baseline_name/

# Compare two baselines
cargo bench -- --baseline old_baseline --save-baseline new_baseline
</code></pre>
<h3 id="baseline-strategy"><a class="header" href="#baseline-strategy">Baseline Strategy</a></h3>
<p><strong>Recommended baselines:</strong></p>
<ol>
<li><strong>main</strong>: Current production performance</li>
<li><strong>release-X.Y.Z</strong>: Tagged release versions</li>
<li><strong>pre-optimization</strong>: Before major optimization work</li>
<li><strong>target</strong>: Performance goals</li>
</ol>
<p><strong>Example workflow:</strong></p>
<pre><code class="language-bash"># Establish target baseline (goals)
cargo bench -- --save-baseline target

# Work on optimizations...
# (make changes, run benchmarks)

# Compare to target
cargo bench -- --baseline target

# If goals met, update main baseline
cargo bench -- --save-baseline main
</code></pre>
<h2 id="continuous-integration"><a class="header" href="#continuous-integration">Continuous Integration</a></h2>
<h3 id="cicd-integration"><a class="header" href="#cicd-integration">CI/CD Integration</a></h3>
<p><strong>GitHub Actions example:</strong></p>
<pre><code class="language-yaml">name: Benchmarks

on:
  pull_request:
    branches: [main]

jobs:
  benchmark:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Install Rust
        uses: actions-rs/toolchain@v1
        with:
          toolchain: stable

      - name: Run benchmarks
        run: |
          cargo bench --bench file_io_benchmark -- --save-baseline pr

      - name: Compare to main
        run: |
          git fetch origin main:main
          git checkout main
          cargo bench --bench file_io_benchmark -- --save-baseline main
          git checkout -
          cargo bench --bench file_io_benchmark -- --baseline main

      - name: Upload results
        uses: actions/upload-artifact@v3
        with:
          name: benchmark-results
          path: target/criterion/
</code></pre>
<h3 id="regression-alerts"><a class="header" href="#regression-alerts">Regression Alerts</a></h3>
<p><strong>Detect regressions in CI:</strong></p>
<pre><code class="language-bash">#!/bin/bash
# scripts/check_benchmarks.sh

# Run benchmarks and save output
cargo bench --bench file_io_benchmark -- --baseline main &gt; bench_output.txt

# Check for regressions
if grep -q "Performance has regressed" bench_output.txt; then
    echo "❌ Performance regression detected!"
    grep "Performance has regressed" bench_output.txt
    exit 1
else
    echo "✅ No performance regressions detected"
    exit 0
fi
</code></pre>
<h2 id="benchmark-best-practices"><a class="header" href="#benchmark-best-practices">Benchmark Best Practices</a></h2>
<h3 id="1-use-representative-workloads"><a class="header" href="#1-use-representative-workloads">1. Use Representative Workloads</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// ✅ Good: Test realistic file sizes
for size_mb in [1, 10, 50, 100, 500, 1000].iter() {
    let test_file = create_test_file(*size_mb);
    benchmark_file_io(&amp;test_file);
}

// ❌ Bad: Only tiny files
let test_file = create_test_file(1);  // Not representative!
<span class="boring">}</span></code></pre></pre>
<h3 id="2-control-variables"><a class="header" href="#2-control-variables">2. Control Variables</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// ✅ Good: Isolate what you're measuring
group.bench_function("compression_only", |b| {
    b.iter(|| {
        // Only benchmark compression, not I/O
        compress_data(black_box(&amp;test_data))
    });
});

// ❌ Bad: Measuring multiple things
group.bench_function("compression_and_io", |b| {
    b.iter(|| {
        let data = read_file(path);  // I/O overhead!
        compress_data(&amp;data)         // Compression
    });
});
<span class="boring">}</span></code></pre></pre>
<h3 id="3-use-black_box-to-prevent-optimization"><a class="header" href="#3-use-black_box-to-prevent-optimization">3. Use <code>black_box</code> to Prevent Optimization</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// ✅ Good: Prevent compiler from eliminating code
b.iter(|| {
    let result = expensive_operation();
    black_box(result);  // Ensures result is not optimized away
});

// ❌ Bad: Compiler may optimize away the work
b.iter(|| {
    expensive_operation();  // Result unused, may be eliminated!
});
<span class="boring">}</span></code></pre></pre>
<h3 id="4-warm-up-before-measuring"><a class="header" href="#4-warm-up-before-measuring">4. Warm Up Before Measuring</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// ✅ Good: Criterion handles warmup automatically
c.bench_function("my_benchmark", |b| {
    // Criterion runs warmup iterations automatically
    b.iter(|| expensive_operation());
});

// ❌ Bad: Manual warmup (unnecessary with Criterion)
for _ in 0..100 {
    expensive_operation();  // Criterion does this for you!
}
<span class="boring">}</span></code></pre></pre>
<h3 id="5-measure-multiple-configurations"><a class="header" href="#5-measure-multiple-configurations">5. Measure Multiple Configurations</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// ✅ Good: Test parameter space
let mut group = c.benchmark_group("chunk_sizes");
for chunk_size in [4096, 8192, 16384, 32768, 65536].iter() {
    group.bench_with_input(
        BenchmarkId::from_parameter(chunk_size),
        chunk_size,
        |b, &amp;size| b.iter(|| process_with_chunk_size(size))
    );
}

// ❌ Bad: Single configuration
c.bench_function("process", |b| {
    b.iter(|| process_with_chunk_size(65536));  // Only one size!
});
<span class="boring">}</span></code></pre></pre>
<h2 id="example-benchmark-analysis"><a class="header" href="#example-benchmark-analysis">Example Benchmark Analysis</a></h2>
<h3 id="scenario-optimizing-chunk-size"><a class="header" href="#scenario-optimizing-chunk-size">Scenario: Optimizing Chunk Size</a></h3>
<p><strong>1. Run baseline benchmarks:</strong></p>
<pre><code class="language-bash">cargo bench --bench file_io_benchmark -- "chunk_sizes" --save-baseline before
</code></pre>
<p><strong>Results:</strong></p>
<pre><code class="language-text">chunk_sizes/regular_io/4096   time:   [82.341 ms 83.129 ms 83.987 ms]
chunk_sizes/regular_io/16384  time:   [62.123 ms 62.891 ms 63.712 ms]
chunk_sizes/regular_io/65536  time:   [52.891 ms 53.523 ms 54.201 ms]
</code></pre>
<p><strong>2. Calculate throughput:</strong></p>
<pre><code class="language-text">File size: 10 MB
4KB chunks:   10 / 0.083129 = 120.3 MB/s
16KB chunks:  10 / 0.062891 = 159.0 MB/s
64KB chunks:  10 / 0.053523 = 186.8 MB/s
</code></pre>
<p><strong>3. Analysis:</strong></p>
<ul>
<li><strong>4 KB chunks</strong>: Slow (120 MB/s) due to syscall overhead</li>
<li><strong>16 KB chunks</strong>: Better (159 MB/s), balanced</li>
<li><strong>64 KB chunks</strong>: Best (187 MB/s), amortizes overhead</li>
</ul>
<p><strong>4. Recommendation:</strong></p>
<p>Use 64 KB chunks for medium files (10-100 MB).</p>
<h3 id="scenario-memory-mapping-threshold"><a class="header" href="#scenario-memory-mapping-threshold">Scenario: Memory Mapping Threshold</a></h3>
<p><strong>1. Run benchmarks across file sizes:</strong></p>
<pre><code class="language-bash">cargo bench --bench file_io_benchmark -- "file_read_methods"
</code></pre>
<p><strong>Results:</strong></p>
<pre><code class="language-text">regular_io/1      time:   [523.45 µs 528.12 µs 533.28 µs]  → 1894 MB/s
memory_mapped/1   time:   [612.34 µs 618.23 µs 624.91 µs]  → 1618 MB/s

regular_io/50     time:   [24.512 ms 24.789 ms 25.091 ms]  → 2017 MB/s
memory_mapped/50  time:   [19.234 ms 19.512 ms 19.812 ms]  → 2563 MB/s

regular_io/100    time:   [52.123 ms 52.891 ms 53.712 ms]  → 1891 MB/s
memory_mapped/100 time:   [38.234 ms 38.712 ms 39.234 ms]  → 2584 MB/s
</code></pre>
<p><strong>2. Crossover analysis:</strong></p>
<ul>
<li><strong>1 MB</strong>: Regular I/O faster (1894 vs 1618 MB/s)</li>
<li><strong>50 MB</strong>: Memory mapping faster (2563 vs 2017 MB/s) - <strong>27% improvement</strong></li>
<li><strong>100 MB</strong>: Memory mapping faster (2584 vs 1891 MB/s) - <strong>37% improvement</strong></li>
</ul>
<p><strong>3. Recommendation:</strong></p>
<p>Use memory mapping for files &gt; 10 MB (threshold between 1-50 MB).</p>
<h2 id="related-topics"><a class="header" href="#related-topics">Related Topics</a></h2>
<ul>
<li>See <a href="performance.html">Performance Optimization</a> for optimization strategies</li>
<li>See <a href="profiling.html">Profiling</a> for CPU and memory profiling</li>
<li>See <a href="thread-pooling.html">Thread Pooling</a> for concurrency tuning</li>
<li>See <a href="resources.html">Resource Management</a> for resource limits</li>
</ul>
<h2 id="summary"><a class="header" href="#summary">Summary</a></h2>
<p>The pipeline's benchmarking suite provides:</p>
<ol>
<li><strong>Comprehensive Coverage</strong>: Read/write operations, chunk sizes, checksums</li>
<li><strong>Statistical Rigor</strong>: Criterion.rs with confidence intervals and regression detection</li>
<li><strong>Baseline Comparison</strong>: Track performance changes over time</li>
<li><strong>CI/CD Integration</strong>: Automated regression detection in pull requests</li>
<li><strong>HTML Reports</strong>: Interactive visualizations and detailed analysis</li>
</ol>
<p><strong>Key Takeaways:</strong></p>
<ul>
<li>Run benchmarks before and after optimizations (<code>--save-baseline</code>)</li>
<li>Use representative workloads (realistic file sizes and configurations)</li>
<li>Look for statistically significant changes (p &lt; 0.05)</li>
<li>Calculate throughput (MB/s) for intuitive performance comparison</li>
<li>Integrate benchmarks into CI/CD for regression prevention</li>
<li>Use HTML reports for detailed analysis and visualization</li>
</ul>
<p><strong>Benchmark Commands:</strong></p>
<pre><code class="language-bash"># Run all benchmarks
cargo bench --bench file_io_benchmark

# Save baseline
cargo bench --bench file_io_benchmark -- --save-baseline main

# Compare to baseline
cargo bench --bench file_io_benchmark -- --baseline main

# Specific group
cargo bench --bench file_io_benchmark -- "file_read_methods"
</code></pre>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../advanced/performance.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next prefetch" href="../advanced/profiling.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../advanced/performance.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next prefetch" href="../advanced/profiling.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="../elasticlunr.min.js"></script>
        <script src="../mark.min.js"></script>
        <script src="../searcher.js"></script>

        <script src="../clipboard.min.js"></script>
        <script src="../highlight.js"></script>
        <script src="../book.js"></script>

        <!-- Custom JS scripts -->



    </div>
    </body>
</html>
